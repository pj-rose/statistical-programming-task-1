

```{r setup, include=FALSE}
a <- scan("bible.txt",what="character",skip=104) ## skip contents
n <- length(a)
a <- a[-((n-2886):n)] ## strip license
a <- a[-grep("[0123456789]:[0123456789]",a)] ## strip out verse numbers
```

## 4 



```{r q4}
split_punct=function(punct_mark,l)
{
position=grep(punct_mark,l) #find the index that contains punctuations marks; return index
x=rep("",length(l)+length(position))  #create a empty x, put strings in it

iis<-position+1:length(position) #indice to put the marks
x[iis]<-substr(l[position],nchar(l[position]),nchar(l[position])) 
y=gsub(punct_mark," ",l) #delete all the marks
x[-iis]<-y


return(x)
}
```

## 5

```{r }
pm=',|\\.|;|:|!|\\?'
a_m=split_punct(pm,a) #a_m is the new list with character and marks individually
```

##6
```{r }
#a
  uni<-unique(a_m) #
  low_uni<-tolower(uni)#turn the capital to lower


#b
  indices<-match(low_uni,tolower(a)) #match
 
#c
  tabulate(,a)
   

```

##7  b is the most commonly words 500.
```{r}
#a
  match(b,a_m)



#b
 matrix() #three column matrix empty
 
 t1<-row()  #index of common words
 t2<-       #t1+1
 
 t3<-
 cbind()
```




##8

##9

##10
